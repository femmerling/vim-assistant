*vim-assistant.txt*    AI coding assistant for Vim/Neovim

Author: Your Name
License: MIT
Version: 1.0.0

==============================================================================
CONTENTS                                                           *vim-assistant*

1. Introduction ................ |vim-assistant-introduction|
2. Installation ................ |vim-assistant-installation|
3. Configuration ................ |vim-assistant-configuration|
4. Commands ..................... |vim-assistant-commands|
5. Key Mappings ................. |vim-assistant-mappings|
6. Troubleshooting .............. |vim-assistant-troubleshooting|

==============================================================================
INTRODUCTION                                           *vim-assistant-introduction*

Vim Assistant is an AI-powered coding assistant that provides intelligent code
completion and generation using local Ollama models with RAG capabilities.

Features:
- AI code completion and generation
- Context-aware using RAG with ChromaDB
- Privacy-first (runs offline)
- Smart file handling
- Optimized for MacVim and Neovim

==============================================================================
INSTALLATION                                           *vim-assistant-installation*

Requirements:
- Vim 8.0+ or Neovim 0.5+
- Python 3.7+
- Ollama installed locally
- Qwen3-coder model

Using Vundle:
>
    Plugin 'your-username/vim-assistant'
<

Manual Installation:
>
    cd ~/.vim/bundle
    git clone https://github.com/your-username/vim-assistant.git
<

Setup:
1. Install Ollama: https://ollama.ai/
2. Pull model: ollama pull qwen3-coder
3. Install dependencies: pip install -r requirements.txt
4. Start Ollama: ollama serve

==============================================================================
CONFIGURATION                                         *vim-assistant-configuration*

Configuration variables:

g:vim_assistant#ollama_url                    *g:vim_assistant#ollama_url*
    Ollama server URL (default: 'http://localhost:11434')

g:vim_assistant#model                         *g:vim_assistant#model*
    Ollama model to use (default: 'qwen3-coder')

g:vim_assistant#buffer_width                  *g:vim_assistant#buffer_width*
    Width of assistant buffer in percentage (default: 20)

g:vim_assistant#max_context_files             *g:vim_assistant#max_context_files*
    Maximum number of files to include in context (default: 50)

g:vim_assistant#chroma_persist_dir            *g:vim_assistant#chroma_persist_dir*
    ChromaDB persistence directory (default: '~/.vim-assistant-chroma')

Example configuration:
>
    let g:vim_assistant#ollama_url = 'http://localhost:11434'
    let g:vim_assistant#model = 'qwen3-coder'
    let g:vim_assistant#buffer_width = 25
<

==============================================================================
COMMANDS                                               *vim-assistant-commands*

:AI                                                    *:AI*
    Open the assistant buffer

:AIClose                                              *:AIClose*
    Close the assistant buffer

:AIToggle                                             *:AIToggle*
    Toggle the assistant buffer

:AIComplete                                            *:AIComplete*
    Get code completion suggestions

:AIGenerate                                            *:AIGenerate*
    Generate new code

:AIUpdateIndex                                         *:AIUpdateIndex*
    Update the codebase index for better context

==============================================================================
KEY MAPPINGS                                           *vim-assistant-mappings*

Default key mappings:

<Leader>ai                                              *<Leader>ai*
    Open/toggle assistant (:AI)

<Leader>ac                                              *<Leader>ac*
    Complete code (:AIComplete)

<Leader>ag                                              *<Leader>ag*
    Generate code (:AIGenerate)

<Leader>at                                              *<Leader>at*
    Toggle assistant (:AIToggle)

Custom key mappings:
>
    " Custom mappings
    nmap <Leader>assistant :AI<CR>
    nmap <Leader>complete :AIComplete<CR>
    nmap <Leader>generate :AIGenerate<CR>
<

==============================================================================
TROUBLESHOOTING                                     *vim-assistant-troubleshooting*

Common Issues:

1. "Error communicating with Ollama"
   - Ensure Ollama is running: ollama serve
   - Check if model is installed: ollama list
   - Verify URL in configuration

2. "Error initializing Chroma"
   - Check Python dependencies: pip install -r requirements.txt
   - Ensure write permissions to chroma directory

3. Slow responses
   - Update codebase index: :AIUpdateIndex
   - Reduce max_context_files in configuration
   - Use smaller model for faster responses

Debug mode:
>
    let g:vim_assistant#debug = 1
<

==============================================================================
vim:tw=78:ts=8:ft=help:norl:
